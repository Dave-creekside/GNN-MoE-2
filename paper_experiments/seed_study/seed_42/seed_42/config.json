{
    "run_name": "seed_42",
    "checkpoint_dir": "paper_experiments/seed_study/seed_42/seed_42",
    "resume_checkpoint": null,
    "seed": 42,
    "architecture_mode": "ghost",
    "vocab_size": 50257,
    "max_seq_length": 512,
    "embed_dim": 128,
    "num_layers": 2,
    "num_heads": 4,
    "num_experts": 2,
    "dropout_rate": 0.1,
    "num_parameters": 14667601,
    "use_hypergraph_coupling": true,
    "use_orthogonal_loss": true,
    "hgnn": {
        "num_layers": 2,
        "strategy": "all_pairs",
        "learnable_edge_weights": false
    },
    "ghost": {
        "num_ghost_experts": 2,
        "ghost_activation_threshold": 0.01,
        "ghost_learning_rate": 0.0001,
        "ghost_activation_schedule": "gradual",
        "saturation_monitoring_window": 100,
        "ghost_lr_coupling": "inverse",
        "ghost_background_learning": false
    },
    "geometric": {
        "enabled": true,
        "geometric_learning_rate": 0.001,
        "expert_learning_rate": 0.0001,
        "rotation_dimensions": 4,
        "orthogonality_weight": 0.5,
        "rotation_efficiency_weight": 0.2,
        "specialization_weight": 0.3,
        "ghost_geometric_threshold": 0.7,
        "ghost_rotation_dimensions": 4,
        "lambda_cognitive_rotations": true,
        "lambda_rotation_scheduling": "curriculum",
        "rotation_matrix_type": "givens",
        "rotation_convergence_threshold": 0.0001,
        "max_rotation_magnitude": 2.0
    },
    "training_mode": "geometric",
    "training_loop": "standard",
    "epochs": 3,
    "batch_size": 2,
    "learning_rate": 0.0001,
    "max_batches_per_epoch": 50,
    "eval_every": 25,
    "max_steps": 150,
    "dataset_source": "huggingface",
    "dataset_name": "Creekside/GRPO-Lambda-ParsedForUnsloth",
    "dataset_config_name": "default",
    "num_train_samples": 2000,
    "num_eval_samples": 400,
    "num_workers_dataloader": 4
}